{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rCNbzGqoxkiv"
   },
   "source": [
    "# Adversarial Attacks and Adversarial Training\n",
    "\n",
    "In this notebook, you will implement both, a common adversarial attack that can \"fool\" models into making mistakes, and a simple defense against such attacks.\n",
    "\n",
    "## Loading the dataset\n",
    "\n",
    "We will be using the MNIST image dataset, which you are already familiar with. The cell below is already implement for you. It loads and preprocesses the training data by normalizing the pixel values to the range `[0, 1]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cMVrts8Qf6fW",
    "outputId": "2ad450b7-e9fd-4264-ae55-22facbc8144c"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load MNIST dataset\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# Normalize images to range [0, 1]\n",
    "x_train, x_test = x_train.astype(np.float32) / 255.0, x_test.astype(np.float32) / 255.0\n",
    "\n",
    "# Expand dimensions for channel consistency (28x28 -> 28x28x1)\n",
    "x_train = np.expand_dims(x_train, axis=-1)\n",
    "x_test = np.expand_dims(x_test, axis=-1)\n",
    "\n",
    "# Convert labels to categorical\n",
    "y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, 10)\n",
    "\n",
    "# Convert to TensorFlow datasets\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(10000).batch(64)\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LhihRZfGw8Xk"
   },
   "source": [
    "## Defining the neural network\n",
    "\n",
    "The cell below defines and trains a small neural network that will act as the target for adversarial attacks through this notebook.\n",
    "\n",
    "After five epochs of training, the accuracy on the training data should be around 97%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AW2dl2yFgR7V"
   },
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Flatten(input_shape=(28, 28, 1)),\n",
    "        tf.keras.layers.Dense(256, activation='relu'),\n",
    "        tf.keras.layers.Dense(128, activation='relu'),\n",
    "        tf.keras.layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Create and train the model\n",
    "model = create_model()\n",
    "model.fit(train_ds, epochs=5, validation_data=test_ds)\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(test_ds)\n",
    "print(f\"Clean Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bCUz4Xjq7GdB"
   },
   "source": [
    "## FGSM attack\n",
    "\n",
    "In the following, we ask you to implement the FGSM attack.\n",
    "The Fast Gradient Sign Method (FGSM) is an adversarial attack algorithm used to generate adversarial examples for neural networks. It was introduced by [Goodfellow et al. in 2014.](https://arxiv.org/abs/1412.6572) The goal of FGSM is to perturb an input to a model in such a way that the model makes a mistake, while the perturbation is small enough to be imperceptible to humans.\n",
    "\n",
    "Here is the FGSM algorithm:\n",
    "\n",
    "1. **Input:**\n",
    "   - A trained model $N$.\n",
    "   - An input example $x$ and its true label $y$.\n",
    "   - A loss function $L(y, N(x))$ that compares the true label $y$ with the prediction $N(x)$ .\n",
    "   - A small perturbation parameter $\\epsilon$.\n",
    "\n",
    "2. **Output:**\n",
    "   - An adversarial example $x'$.\n",
    "\n",
    "3. **Algorithm:**\n",
    "   - Compute the gradient of the loss with respect to the input $x$: $\\nabla_x L(y, N(x))$.\n",
    "   - Create the adversarial example by adding a small perturbation in the direction of the gradient's sign:\n",
    "     $$\n",
    "     x' = \\text{clip}(x + \\epsilon \\cdot \\text{sign}(\\nabla_x L(y, N(x)))).\n",
    "     $$\n",
    "   - Here, the function $\\text{clip}$ clips the resulting example $x'$ to ensure it is within the valid range for input values (e.g., pixel values between 0 and 255 for images).\n",
    "\n",
    "The perturbation $\\epsilon \\cdot \\text{sign}(\\nabla_x L(y, N(x)))$ is designed to increase the loss, thereby making the model more likely to misclassify the input. The sign function ensures that the perturbation is small and uniform in each dimension.\n",
    "\n",
    "This simple yet effective method highlights the vulnerability of neural networks to adversarial examples and has inspired further research into more sophisticated attack and defense mechanisms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yEpquPY1fSYQ"
   },
   "source": [
    "## Implementing FGSM Attacks\n",
    "\n",
    "To implement this algorithm, you need a few advanced Tensorflow utilities.\n",
    "Remember that we are searching for a perturbation of the input, in this case an image, that causes the model to misclassify the input. For this, we have to compute the gradient of the loss function with respect to the input image. So far, we have always abstracted away the part of computing gradients and optimizing the loss function behind a call to `model.fit`. Now, we will introduce you to a more direct approach.\n",
    "\n",
    "### Computing gradients with tensorflow\n",
    "\n",
    "In Tensorflow, we can record operations for automatic differentiation using the `tf.GradientTape` context manager. You can construct a gradient tape using `with ... as ...:`:\n",
    "\n",
    "```python\n",
    "with tf.GradientTape() as tape:\n",
    "    # Do something here\n",
    "    # ...\n",
    "```\n",
    "\n",
    "You can record operations that happen within the context manager by watching them using `GradientTape.watch`. Once you have recorded all the operations that you are interested in, you can compute the gradient of the tape using `GradientTape.gradient`. `GradientTape.gradient` takes as argument the variable you want to compute the gradient of, followed by the variable with respect to which you wish to compute the gradient.\n",
    "\n",
    "Let's look at an example. Say you want to compute the gradient of the function `y = x * x` for `x = 42`. Using a gradient tape, you would do the following:\n",
    "\n",
    "```python\n",
    "# Define x:\n",
    "x = tf.constant(42.0)\n",
    "with tf.GradientTape() as tape:\n",
    "    tape.watch(x)\n",
    "    y = x * x\n",
    "# Compute the gradient.\n",
    "dy_dx = tape.gradient(y, x)\n",
    "```\n",
    "\n",
    "You can learn more about `tf.GradienTape` on its [documentation page](https://www.tensorflow.org/api_docs/python/tf/GradientTape).\n",
    "To get familiar with `tf.GradientTape`, use it below to compute the gradient of `cos(x * x)` at `x = 42`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7k-yxXrpa_3S",
    "outputId": "9ba403cc-deba-414d-b389-94412b3d4bc2"
   },
   "outputs": [],
   "source": [
    "x = tf.constant(42.0)\n",
    "with tf.GradientTape() as tape:\n",
    "    # Watch x and compute cos(x*x) here (you can use tf.cos).\n",
    "    ...\n",
    "\n",
    "# Compute the gradient:\n",
    "dy_dx = ...\n",
    "\n",
    "# This should yield something close to 84.\n",
    "dy_dx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LSRyxPWI7v4f"
   },
   "source": [
    "### Computing gradients of neural networks\n",
    "\n",
    "Let's look at a more complex example: Computing the gradient of the loss with `GradientTape`. We showcase this below.\n",
    "\n",
    "1. You take an image, its corresponding label, and the neural network.\n",
    "2. The gradient tape is used to record the calculation of the prediction by the neural network.\n",
    "3. When computing the gradient we do this with respect to the given image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-FroIacf7ubt"
   },
   "outputs": [],
   "source": [
    "def compute_gradient_network(image, label, model):\n",
    "    image = tf.convert_to_tensor(image, dtype=tf.float32)\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(image)\n",
    "        prediction = model(image)\n",
    "        loss = tf.keras.losses.categorical_crossentropy(label, prediction)\n",
    "    return tape.gradient(loss, image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5wm7-Tlnb2Zo"
   },
   "source": [
    "## Clipping\n",
    "\n",
    "We also need the function `tf.clip_by_value` from tensorflow. When you apply the perturbation to the image, it is possible that the perturbation pushes some pixels' values outside of their defined range (e.g. smaller than `0.0` or larger than `1.0`). To counteract this, we have to clip the perturbed image back to their defined range. We do this using `tf.clip_by_value`: it clips tensor values to a specified min and max. `clip_by_value` has the following signature:\n",
    "```python\n",
    "tf.clip_by_value(\n",
    "    t, clip_value_min, clip_value_max, name=None\n",
    ")\n",
    "```\n",
    "`t` is the tensor whose values you wish to clip, `clip_value_min` is the minimum value of the desired value range, and `clip_value_max` is its maximum.\n",
    "\n",
    "So, if you want to clip a tensor `x` to the range `[-1, 1]`, you can do this by calling:\n",
    "\n",
    "```python\n",
    "tf.clip_by_value(x, -1, 1)\n",
    "```\n",
    "---\n",
    "\n",
    "With these tools, you have everything you need to implement `fgsm_attack` below. Use `compute_gradient_network` from above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sGGxFlHWgU15"
   },
   "outputs": [],
   "source": [
    "def fgsm_attack(image, label, model, epsilon=0.2):\n",
    "    # Implement the FGSM attack here and return an adversarial image.\n",
    "    # ...\n",
    "    adversarial_image = ...\n",
    "    return adversarial_image\n",
    "\n",
    "def evaluate_adversarial_examples(model, dataset, epsilon=0.2):\n",
    "    total, correct = 0, 0\n",
    "    for images, labels in dataset:\n",
    "        adv_images = fgsm_attack(images, labels, model, epsilon)\n",
    "        predictions = model.predict(adv_images)\n",
    "        correct += np.sum(np.argmax(predictions, axis=1) == np.argmax(labels.numpy(), axis=1))\n",
    "        total += labels.shape[0]\n",
    "    print(f\"Adversarial Accuracy (ε={epsilon}): {100 * correct / total:.2f}%\")\n",
    "\n",
    "evaluate_adversarial_examples(model, test_ds, epsilon=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J95LpgpbhFYs"
   },
   "source": [
    "In the cell below, we test your FGSM implementation on a few sample images.\n",
    "The plot below displays the model's predictions for the original images in the first row, and the predictions for the perturbed images in the second one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 438
    },
    "id": "dB3YI9Dphc-2",
    "outputId": "749cc51a-951a-4eb9-b4b6-8e1e7642914c"
   },
   "outputs": [],
   "source": [
    "# Select a sample batch of test images\n",
    "sample_images, sample_labels = next(iter(test_ds))\n",
    "sample_images = sample_images[:5]  # Take 5 images\n",
    "sample_labels = sample_labels[:5]\n",
    "\n",
    "# Generate adversarial examples\n",
    "adv_sample = fgsm_attack(sample_images, sample_labels, model, epsilon=0.2)\n",
    "\n",
    "# Get predictions for both original and adversarial images\n",
    "original_preds = model.predict(sample_images)\n",
    "adversarial_preds = model.predict(adv_sample)\n",
    "\n",
    "# Convert predictions to class labels\n",
    "original_labels = np.argmax(original_preds, axis=1)\n",
    "adversarial_labels = np.argmax(adversarial_preds, axis=1)\n",
    "\n",
    "# Plot original and adversarial images with predicted labels\n",
    "fig, axes = plt.subplots(2, 5, figsize=(10, 5))\n",
    "\n",
    "for i in range(5):\n",
    "    # Plot original image\n",
    "    axes[0, i].imshow(sample_images[i].numpy().squeeze(), cmap=\"gray\")\n",
    "    axes[0, i].set_title(f\"Orig: {original_labels[i]}\")\n",
    "    axes[0, i].axis(\"off\")\n",
    "\n",
    "    # Plot adversarial image\n",
    "    axes[1, i].imshow(adv_sample[i].numpy().squeeze(), cmap=\"gray\")\n",
    "    axes[1, i].set_title(f\"Adv: {adversarial_labels[i]}\")\n",
    "    axes[1, i].axis(\"off\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1dPJJaHCwzSg"
   },
   "source": [
    "Next, we ask you to implement adversarial training to defend the model against adversarial attacks.\n",
    "\n",
    "To refresh your memory, adversarial training works as follows:\n",
    "\n",
    "1. Sample a batch of images and their labels.\n",
    "2. Perturb the images using an adversarial attack. Use `fgsm_attack` from above for this!\n",
    "3. Obtain predictions for the perturbed images.\n",
    "4. Obtain predictions for the unperturbed images.\n",
    "5. Compute the loss for both the perturbed and unperturbed images, and average them.\n",
    "6. Compute the gradient of the averaged loss and optimize it using an optimizer.\n",
    "\n",
    "Take inspiration from the `standard_training` function below. `standard_training` shows you how to implement the standard neural network training loop with a `GradientTape`. Here are a few important points to take away:\n",
    "- You have to call `model` with `training_True` when making a prediction. This ensures that the model parameters are watched by the gradient tape, without explicitly calling `tape.watch`.\n",
    "- To compute the gradient of the loss function with respect to the model's parameters, we have to pass them as the second argument to `tape.gradient`. THe model parameters are stored in `model.trainable_variables`.\n",
    "- To use the gradients with the optimizer, use `optimizer.apply_gradients`. This function expects a list of tuples, where the first element is the gradient, and the second element is the variable with respect to which the gardient was computed. Such a list can be created using the `zip` function as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "byYHYCOBW8Vl"
   },
   "outputs": [],
   "source": [
    "def standard_training(model, train_ds, epochs=5):\n",
    "    optimizer = tf.keras.optimizers.Adam()\n",
    "    loss_fn = tf.keras.losses.CategoricalCrossentropy()\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}\")\n",
    "        for images, labels in train_ds:\n",
    "            with tf.GradientTape() as tape:\n",
    "                # Compute predictions using the current parameters. Note the\n",
    "                # `training=True` flag.\n",
    "                predictions = model(images, training=True)\n",
    "                loss = loss_fn(labels, predictions)\n",
    "            # Compute the gradient of the loss with respect to the\n",
    "            # model parameters (stored in model.trainable_variables).\n",
    "            gradients = tape.gradient(loss, model.trainable_variables)\n",
    "            # Use the computed gradients with the optimizer. Note that\n",
    "            # apply_gradients expects a list of tuples where the first element\n",
    "            optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "standard_model = create_model()\n",
    "standard_training(standard_model, train_ds, epochs=5)\n",
    "\n",
    "print(\"Standard Model Accuracy on Clean Images:\")\n",
    "loss, accuracy = standard_model.evaluate(test_ds)\n",
    "print(f\"Clean Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BcxHNVJfcKsM"
   },
   "source": [
    "With all of the above in mind, go ahead and implement the missing parts of `adversarial_training` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mdxRqLgdgbmN"
   },
   "outputs": [],
   "source": [
    "def adversarial_training(model, train_ds, epsilon=0.2, epochs=5):\n",
    "    optimizer = tf.keras.optimizers.Adam()\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}\")\n",
    "        for images, labels in train_ds:\n",
    "            # Implement adversarial training here. Take inspiration from above.\n",
    "            # ...\n",
    "        evaluate_adversarial_examples(model, test_ds, epsilon)\n",
    "\n",
    "# Create and train a robust model\n",
    "robust_model = create_model()\n",
    "adversarial_training(robust_model, train_ds, epsilon=0.2, epochs=5)\n",
    "\n",
    "print(\"Robust Model Accuracy on Clean Images:\")\n",
    "loss, accuracy = robust_model.evaluate(test_ds)\n",
    "print(f\"Clean Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "print(\"Robust Model Accuracy on Adversarial Examples:\")\n",
    "evaluate_adversarial_examples(robust_model, test_ds, epsilon=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FZ2Aj722F61L"
   },
   "source": [
    "Now, let's see whether our new model is more robust against the FGSM attack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cHSDRjVAGCfT"
   },
   "outputs": [],
   "source": [
    "# Select a sample batch of test images\n",
    "sample_images, sample_labels = next(iter(test_ds))\n",
    "sample_images = sample_images[:5]  # Take 5 images\n",
    "sample_labels = sample_labels[:5]\n",
    "\n",
    "# Generate adversarial examples\n",
    "adv_sample = fgsm_attack(sample_images, sample_labels, robust_model, epsilon=0.2)\n",
    "\n",
    "# Get predictions for both original and adversarial images\n",
    "original_preds = robust_model.predict(sample_images)\n",
    "adversarial_preds = robust_model.predict(adv_sample)\n",
    "\n",
    "# Convert predictions to class labels\n",
    "original_labels = np.argmax(original_preds, axis=1)\n",
    "adversarial_labels = np.argmax(adversarial_preds, axis=1)\n",
    "\n",
    "# Plot original and adversarial images with predicted labels\n",
    "fig, axes = plt.subplots(2, 5, figsize=(10, 5))\n",
    "\n",
    "for i in range(5):\n",
    "    # Plot original image\n",
    "    axes[0, i].imshow(sample_images[i].numpy().squeeze(), cmap=\"gray\")\n",
    "    axes[0, i].set_title(f\"Orig: {original_labels[i]}\")\n",
    "    axes[0, i].axis(\"off\")\n",
    "\n",
    "    # Plot adversarial image\n",
    "    axes[1, i].imshow(adv_sample[i].numpy().squeeze(), cmap=\"gray\")\n",
    "    axes[1, i].set_title(f\"Adv: {adversarial_labels[i]}\")\n",
    "    axes[1, i].axis(\"off\")\n",
    "\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
