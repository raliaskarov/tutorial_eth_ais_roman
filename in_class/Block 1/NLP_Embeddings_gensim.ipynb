{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "Vwxks-AzPjid",
   "metadata": {
    "id": "Vwxks-AzPjid"
   },
   "source": [
    "# Embeddings using Gensim Pre-trained Models\n",
    "In this notebook, we will look at the embeddings that are made available through Gensim. Gensim provides access to a variety of pre-trained word embedding models that are useful for a range of NLP tasks such as text classification, clustering, semantic analysis, and more. These models are trained on large datasets and can be used out-of-the-box for various applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "YVMUYGGUQZ6O",
   "metadata": {
    "id": "YVMUYGGUQZ6O"
   },
   "outputs": [],
   "source": [
    "import gensim.downloader as api"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bjLuQlTGQb2Y",
   "metadata": {
    "id": "bjLuQlTGQb2Y"
   },
   "source": [
    "  First, we can have a look at all the models that are available through Gensim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lNvC83rgQba6",
   "metadata": {
    "id": "lNvC83rgQba6"
   },
   "outputs": [],
   "source": [
    "models = api.info()['models'].keys()\n",
    "print(models)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "w6WcKhwogg7-",
   "metadata": {
    "id": "w6WcKhwogg7-"
   },
   "source": [
    "We will load the model `fasttext-wiki-news-subwords-300`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99T-eHhwgjP4",
   "metadata": {
    "id": "99T-eHhwgjP4"
   },
   "outputs": [],
   "source": [
    "ft_model = api.load('fasttext-wiki-news-subwords-300')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "muU1sPbegyEI",
   "metadata": {
    "id": "muU1sPbegyEI"
   },
   "source": [
    "This model provides different functions. For instance, we can get the embedding\n",
    "for a certain word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "l-G0MeS7gtQU",
   "metadata": {
    "id": "l-G0MeS7gtQU"
   },
   "outputs": [],
   "source": [
    "vector = ft_model['queen']\n",
    "print(f\"Vector for 'queen':\\n{vector}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bxWuUXEyhODr",
   "metadata": {
    "id": "bxWuUXEyhODr"
   },
   "source": [
    "We can find the most similar words to a word we specify."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "zRadFiNxhM6w",
   "metadata": {
    "id": "zRadFiNxhM6w"
   },
   "outputs": [],
   "source": [
    "similar_words = ft_model.most_similar('queen', topn=5)\n",
    "print(f\"Most similar words to 'queen':\\n{similar_words}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0_EWr5MJh0BX",
   "metadata": {
    "id": "0_EWr5MJh0BX"
   },
   "source": [
    "We can calculate the similarity between two words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "S2MlJuQ9hywq",
   "metadata": {
    "id": "S2MlJuQ9hywq"
   },
   "outputs": [],
   "source": [
    "similarity = ft_model.similarity('woman', 'man')\n",
    "print(f\"Similarity between 'woman' and 'man':\\n{similarity}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Z9_LSvsGh79K",
   "metadata": {
    "id": "Z9_LSvsGh79K"
   },
   "source": [
    "Or the distance (dissimliarity) between two words.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lLbR8Xquh4FU",
   "metadata": {
    "id": "lLbR8Xquh4FU"
   },
   "outputs": [],
   "source": [
    "distance = ft_model.distance('woman', 'man')\n",
    "print(f\"Distance between 'woman' and 'man':\\n{distance}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "T5ve6dFlhfNs",
   "metadata": {
    "id": "T5ve6dFlhfNs"
   },
   "source": [
    "We can specify a list and find the word that does not match the group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Zfa8Wbf2her6",
   "metadata": {
    "id": "Zfa8Wbf2her6"
   },
   "outputs": [],
   "source": [
    "odd_word = ft_model.doesnt_match(['breakfast', 'lunch', 'dinner', 'car'])\n",
    "print(f\"Odd word out: {odd_word}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "RZSGBA3RjRXw",
   "metadata": {
    "id": "RZSGBA3RjRXw"
   },
   "source": [
    "We can also find words by analogy (e.g., \"man is to king as woman is to ___\"):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "LxJlJVqajMM2",
   "metadata": {
    "id": "LxJlJVqajMM2"
   },
   "outputs": [],
   "source": [
    "analogy = ft_model.most_similar(positive=['king', 'woman'], negative=['man'], topn=1)\n",
    "print(f\"Man is to king as woman is to: {analogy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2816ed0b-79af-443f-84b6-38088c14fbb7",
   "metadata": {},
   "source": [
    "To better understand what is going on, we do the math behind the above function call. The embedding of  `man` is subtracted from the embedding of `king` to give the \"royalty\" direction. If we add that the the embedding value of `woman`, we get the `queen_vector`, and expect this to be close to the embedding of `queen`. Let's see:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad42cf0-149c-41ae-919e-7111378c75ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "queen_vector = ft_model['king'] - ft_model['man'] + ft_model['woman']\n",
    "ft_model.most_similar(queen_vector, topn=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tSpFTJZCiMpD",
   "metadata": {
    "id": "tSpFTJZCiMpD"
   },
   "source": [
    "**Exercise:**\n",
    "\n",
    "Now it is your turn. Complete the following tasks:\n",
    "1.  Find the 3 most similar words to the word 'university'.\n",
    "2.  Calculate the similarity between the words 'computer' and 'robot'. Compare it to the similarity between 'computer' and 'tablet'.\n",
    "3.  Calculate the distance between 'queen' and 'king. Compare it to the distance between 'prince' and 'princess'.\n",
    "4.  Find the odd word from the list `['Monday', 'Tuesday', 'March', 'Wednesday']`\n",
    "5.  Find the analogy for: \"man is to father as woman is to ___ \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec69fec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
