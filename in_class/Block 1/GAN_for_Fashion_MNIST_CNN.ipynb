{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7245c2ab",
   "metadata": {},
   "source": [
    "# Generative Adversarial Network for Fashion-MNIST\n",
    "We want to try to generate artificial data - in this example, images of the 10 categories of clothing items. The generated images should be created in such a way that they cannot be distinguished from real images. We use a generator for the creation, analogous to the decoder of an autoencoder, and also generate the codes randomly. To distinguish between real and artificial data, we also use a deep neural network that solves a binary classification problem. This second network is called a discriminator or adversary.\n",
    "\n",
    "The two parts of the network (generator and discriminator) are trained alternately"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e749d0cf",
   "metadata": {},
   "source": [
    "# Preparations\n",
    "## Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142894a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4c406e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout\n",
    "from tensorflow.keras.layers import Conv2D, Flatten, Input, MaxPool2D # neue Layers!\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "from tensorflow.keras.utils import to_categorical, plot_model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, TensorBoard\n",
    "from tensorflow.keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b58813",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.random.set_seed(123)\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6c4d9a",
   "metadata": {},
   "source": [
    "## Prepare Data\n",
    "We do the same pre-processing steps as you already know:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4d9450",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Laden:\n",
    "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "(train_val_images, train_val_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
    "\n",
    "# Skalieren:\n",
    "train_val_images = train_val_images / 255.0\n",
    "\n",
    "# Aufteilen training / validation\n",
    "train_images, val_images = train_test_split(\n",
    "    train_val_images, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d5ee45f",
   "metadata": {},
   "source": [
    "We randomly choose 1000 samples to allow for a faster training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4277f835",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "dataset = tf.data.Dataset.from_tensor_slices(train_images.astype(np.float32)).shuffle(1000)\n",
    "dataset = dataset.batch(batch_size, drop_remainder=True).prefetch(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2e8585",
   "metadata": {},
   "source": [
    "# The Generative Adversarial Network (GAN)\n",
    "## Model Definition\n",
    "Next, we define the model. We will choose a coding size of 30, and start off with very similar architectures as we had for the Autoencoder. We use the encoder part for the discriminator, and the decoder part for the generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0850504",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "codings_size = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c60722d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generator, similar to the decoding part of the Autoencoder\n",
    "generator = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape = (30)),\n",
    "    tf.keras.layers.Dense(7*7*16, activation= 'relu'),\n",
    "    tf.keras.layers.Reshape(target_shape = (7, 7, 16)),\n",
    "    tf.keras.layers.Conv2D(32, kernel_size = (3,3), activation = 'selu', padding = 'same'),\n",
    "    tf.keras.layers.UpSampling2D((2,2)),\n",
    "    tf.keras.layers.Conv2D(16, kernel_size = (3,3), activation = 'selu', padding = 'same'),\n",
    "    tf.keras.layers.UpSampling2D((2,2)),\n",
    "    tf.keras.layers.Conv2D(1, kernel_size = (3,3), activation = 'sigmoid', padding = 'same'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e8604d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# discriminator - a typical CNN architecture for a classification task. Here, we have a binary classification task.\n",
    "discriminator = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape = (28, 28, 1)),\n",
    "    tf.keras.layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=2),  # output: 14 × 14 x 16\n",
    "    tf.keras.layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=2),  # output: 7 × 7 x 32\n",
    "    tf.keras.layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(30, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# compile the discriminator.\n",
    "discriminator.compile(loss=\"binary_crossentropy\", optimizer=\"rmsprop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9367f655",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The overall GAN consists of a generator and a discriminator. \n",
    "# For the training process, we set the discriminator to non-trainable, so that when we train the gan,\n",
    "# only the parameters of the generator will change.\n",
    "discriminator.trainable = False\n",
    "gan = tf.keras.Sequential([generator, discriminator])\n",
    "gan.compile(loss=\"binary_crossentropy\", optimizer=\"rmsprop\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f606d2",
   "metadata": {},
   "source": [
    "## Training / Fitting\n",
    "To better track the progress of the training, we want to display a few generated images after each epoch. For this, we define this helper function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5fe831c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_multiple_images(images, n_cols=None):\n",
    "    n_cols = n_cols or len(images)\n",
    "    n_rows = (len(images) - 1) // n_cols + 1\n",
    "    if images.shape[-1] == 1:\n",
    "        images = images.squeeze(axis=-1)\n",
    "    plt.figure(figsize=(n_cols, n_rows))\n",
    "    for index, image in enumerate(images):\n",
    "        plt.subplot(n_rows, n_cols, index + 1)\n",
    "        plt.imshow(image, cmap=\"binary\")\n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f2f724",
   "metadata": {},
   "source": [
    "The following function alternately trains the `discriminator` and the `generator`.\n",
    "\n",
    "* To train the `discriminator`, we generate data from random codes using a random number generator via `tf.random.normal`, and \"decode\" them to images using the `generator`. The real and synthetic data with the corresponding labels are then the training data for the `discriminator`.\n",
    "* To train the ` generator`, we use random codes and the current state of the `discriminator`. The `generator` should be trained in such a way that the `discriminator` does not recognize the synthetic data, i.e., it (incorrectly) classifies them as real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b18741",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_gan(gan, dataset, batch_size, codings_size, n_epochs):\n",
    "    generator, discriminator = gan.layers\n",
    "    for epoch in range(n_epochs):\n",
    "        print(f\"Epoch {epoch + 1}/{n_epochs}\")\n",
    "        for X_batch in dataset:\n",
    "            \n",
    "            # phase 1 - training the discriminator\n",
    "            random_input = tf.random.normal(shape=[batch_size, codings_size])  # random numbers\n",
    "            generated_images = generator(random_input)  # use discriminator as is\n",
    "            X_fake_and_real = tf.concat([tf.squeeze(generated_images), X_batch], axis=0)\n",
    "            # Labels: 0 => synthetic data, 1 => real data\n",
    "            y1 = tf.constant([[0.]] * batch_size + [[1.]] * batch_size, dtype=tf.float64)\n",
    "            discriminator.train_on_batch(X_fake_and_real, y1)\n",
    "            \n",
    "            # phase 2 - training the generator\n",
    "            random_input = tf.random.normal(shape=[batch_size, codings_size])\n",
    "            # we want to train the generator such that the discriminator thinks the generated images are real!\n",
    "            y2 = tf.constant([[1.]] * batch_size, dtype=tf.float64)\n",
    "            gan.train_on_batch(random_input, y2)\n",
    "            \n",
    "        # extra code — plot images during training\n",
    "        plot_multiple_images(generated_images.numpy(), 8)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b75eefc0",
   "metadata": {},
   "source": [
    "The following instruction will train this GAN over 5 epochs - this is typically enough to see some interesting things happen.\n",
    "\n",
    "**This Training will take some time!!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb074bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gan(gan, dataset, batch_size, codings_size, n_epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ed54c2-b8fc-41ef-8428-85e80b10fa13",
   "metadata": {},
   "source": [
    "**Exercise:** What do you observe in the images above? What seems to work well, what not?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "389840f0-0c8d-4878-92a7-4a2f8e643b1e",
   "metadata": {},
   "source": [
    "**Exercise:** Can you get similar results with less parameters? Play around with the models, and report your findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b1364a-0f7f-439e-a046-71c0607f0742",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
